{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqOf1ShVyssX",
        "outputId": "7e176557-09b2-46f0-825d-9e07deb24c2d"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        " \n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate\n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        " \n",
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        " \n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        " \n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        " \n",
        "model.summary()\n",
        " \n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        " \n",
        "#training\n",
        "batch_size = 64\n",
        " \n",
        "opt_rms = keras.optimizers.RMSprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n",
        " \n",
        "#testing\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Epoch 1/125\n",
            "781/781 [==============================] - 31s 34ms/step - loss: 2.3285 - accuracy: 0.3462 - val_loss: 1.5704 - val_accuracy: 0.5447\n",
            "Epoch 2/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 1.3123 - accuracy: 0.5723 - val_loss: 0.9389 - val_accuracy: 0.7080\n",
            "Epoch 3/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 1.1090 - accuracy: 0.6398 - val_loss: 1.3749 - val_accuracy: 0.6263\n",
            "Epoch 4/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.9783 - accuracy: 0.6910 - val_loss: 0.9541 - val_accuracy: 0.7162\n",
            "Epoch 5/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.9135 - accuracy: 0.7136 - val_loss: 0.8837 - val_accuracy: 0.7431\n",
            "Epoch 6/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.8691 - accuracy: 0.7302 - val_loss: 0.8008 - val_accuracy: 0.7615\n",
            "Epoch 7/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.8337 - accuracy: 0.7466 - val_loss: 0.7457 - val_accuracy: 0.7895\n",
            "Epoch 8/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7895 - accuracy: 0.7644 - val_loss: 0.7526 - val_accuracy: 0.7825\n",
            "Epoch 9/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7728 - accuracy: 0.7740 - val_loss: 0.6873 - val_accuracy: 0.8032\n",
            "Epoch 10/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.7568 - accuracy: 0.7768 - val_loss: 0.7163 - val_accuracy: 0.7945\n",
            "Epoch 11/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7368 - accuracy: 0.7872 - val_loss: 0.6958 - val_accuracy: 0.8041\n",
            "Epoch 12/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.7300 - accuracy: 0.7878 - val_loss: 0.6711 - val_accuracy: 0.8142\n",
            "Epoch 13/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.7088 - accuracy: 0.7988 - val_loss: 0.7395 - val_accuracy: 0.8048\n",
            "Epoch 14/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6985 - accuracy: 0.8032 - val_loss: 0.6963 - val_accuracy: 0.8095\n",
            "Epoch 15/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6964 - accuracy: 0.8081 - val_loss: 0.6549 - val_accuracy: 0.8270\n",
            "Epoch 16/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6791 - accuracy: 0.8097 - val_loss: 0.7388 - val_accuracy: 0.8038\n",
            "Epoch 17/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6734 - accuracy: 0.8094 - val_loss: 0.6675 - val_accuracy: 0.8211\n",
            "Epoch 18/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6695 - accuracy: 0.8150 - val_loss: 0.6925 - val_accuracy: 0.8138\n",
            "Epoch 19/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6712 - accuracy: 0.8141 - val_loss: 0.6256 - val_accuracy: 0.8359\n",
            "Epoch 20/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6559 - accuracy: 0.8231 - val_loss: 0.6830 - val_accuracy: 0.8244\n",
            "Epoch 21/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6509 - accuracy: 0.8210 - val_loss: 0.6462 - val_accuracy: 0.8328\n",
            "Epoch 22/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6561 - accuracy: 0.8210 - val_loss: 0.6585 - val_accuracy: 0.8259\n",
            "Epoch 23/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6587 - accuracy: 0.8205 - val_loss: 0.6637 - val_accuracy: 0.8272\n",
            "Epoch 24/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6449 - accuracy: 0.8251 - val_loss: 0.6116 - val_accuracy: 0.8434\n",
            "Epoch 25/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6353 - accuracy: 0.8292 - val_loss: 0.6142 - val_accuracy: 0.8404\n",
            "Epoch 26/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6449 - accuracy: 0.8275 - val_loss: 0.6256 - val_accuracy: 0.8426\n",
            "Epoch 27/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6320 - accuracy: 0.8299 - val_loss: 0.5907 - val_accuracy: 0.8507\n",
            "Epoch 28/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6315 - accuracy: 0.8318 - val_loss: 0.5762 - val_accuracy: 0.8552\n",
            "Epoch 29/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6357 - accuracy: 0.8299 - val_loss: 0.6897 - val_accuracy: 0.8252\n",
            "Epoch 30/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6278 - accuracy: 0.8328 - val_loss: 0.5809 - val_accuracy: 0.8560\n",
            "Epoch 31/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6288 - accuracy: 0.8331 - val_loss: 0.6158 - val_accuracy: 0.8430\n",
            "Epoch 32/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6227 - accuracy: 0.8366 - val_loss: 0.6024 - val_accuracy: 0.8459\n",
            "Epoch 33/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6200 - accuracy: 0.8363 - val_loss: 0.6611 - val_accuracy: 0.8335\n",
            "Epoch 34/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6108 - accuracy: 0.8431 - val_loss: 0.6223 - val_accuracy: 0.8436\n",
            "Epoch 35/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6147 - accuracy: 0.8387 - val_loss: 0.6165 - val_accuracy: 0.8465\n",
            "Epoch 36/125\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6145 - accuracy: 0.8422 - val_loss: 0.6195 - val_accuracy: 0.8449\n",
            "Epoch 37/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6158 - accuracy: 0.8376 - val_loss: 0.6254 - val_accuracy: 0.8454\n",
            "Epoch 38/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6056 - accuracy: 0.8431 - val_loss: 0.5863 - val_accuracy: 0.8542\n",
            "Epoch 39/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6047 - accuracy: 0.8419 - val_loss: 0.6194 - val_accuracy: 0.8464\n",
            "Epoch 40/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6203 - accuracy: 0.8365 - val_loss: 0.5733 - val_accuracy: 0.8558\n",
            "Epoch 41/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6085 - accuracy: 0.8450 - val_loss: 0.6014 - val_accuracy: 0.8509\n",
            "Epoch 42/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6043 - accuracy: 0.8428 - val_loss: 0.5694 - val_accuracy: 0.8580\n",
            "Epoch 43/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6042 - accuracy: 0.8434 - val_loss: 0.6180 - val_accuracy: 0.8426\n",
            "Epoch 44/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5992 - accuracy: 0.8437 - val_loss: 0.7270 - val_accuracy: 0.8121\n",
            "Epoch 45/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6030 - accuracy: 0.8446 - val_loss: 0.5732 - val_accuracy: 0.8602\n",
            "Epoch 46/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6035 - accuracy: 0.8438 - val_loss: 0.6274 - val_accuracy: 0.8484\n",
            "Epoch 47/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6011 - accuracy: 0.8434 - val_loss: 0.5788 - val_accuracy: 0.8579\n",
            "Epoch 48/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5915 - accuracy: 0.8502 - val_loss: 0.5858 - val_accuracy: 0.8576\n",
            "Epoch 49/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5967 - accuracy: 0.8474 - val_loss: 0.5807 - val_accuracy: 0.8574\n",
            "Epoch 50/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5914 - accuracy: 0.8482 - val_loss: 0.6381 - val_accuracy: 0.8419\n",
            "Epoch 51/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6043 - accuracy: 0.8426 - val_loss: 0.5754 - val_accuracy: 0.8622\n",
            "Epoch 52/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5866 - accuracy: 0.8493 - val_loss: 0.6260 - val_accuracy: 0.8466\n",
            "Epoch 53/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5819 - accuracy: 0.8491 - val_loss: 0.5781 - val_accuracy: 0.8613\n",
            "Epoch 54/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5867 - accuracy: 0.8490 - val_loss: 0.6097 - val_accuracy: 0.8505\n",
            "Epoch 55/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5892 - accuracy: 0.8510 - val_loss: 0.6298 - val_accuracy: 0.8444\n",
            "Epoch 56/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5866 - accuracy: 0.8501 - val_loss: 0.6125 - val_accuracy: 0.8514\n",
            "Epoch 57/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5854 - accuracy: 0.8493 - val_loss: 0.5727 - val_accuracy: 0.8617\n",
            "Epoch 58/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5859 - accuracy: 0.8526 - val_loss: 0.5750 - val_accuracy: 0.8562\n",
            "Epoch 59/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5733 - accuracy: 0.8545 - val_loss: 0.5514 - val_accuracy: 0.8664\n",
            "Epoch 60/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5836 - accuracy: 0.8520 - val_loss: 0.6234 - val_accuracy: 0.8492\n",
            "Epoch 61/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5797 - accuracy: 0.8533 - val_loss: 0.5912 - val_accuracy: 0.8564\n",
            "Epoch 62/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5800 - accuracy: 0.8509 - val_loss: 0.6192 - val_accuracy: 0.8522\n",
            "Epoch 63/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5828 - accuracy: 0.8523 - val_loss: 0.5429 - val_accuracy: 0.8687\n",
            "Epoch 64/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5718 - accuracy: 0.8565 - val_loss: 0.5729 - val_accuracy: 0.8627\n",
            "Epoch 65/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5759 - accuracy: 0.8544 - val_loss: 0.6005 - val_accuracy: 0.8538\n",
            "Epoch 66/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5754 - accuracy: 0.8554 - val_loss: 0.6054 - val_accuracy: 0.8542\n",
            "Epoch 67/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5704 - accuracy: 0.8570 - val_loss: 0.5950 - val_accuracy: 0.8559\n",
            "Epoch 68/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5712 - accuracy: 0.8574 - val_loss: 0.5831 - val_accuracy: 0.8610\n",
            "Epoch 69/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5736 - accuracy: 0.8576 - val_loss: 0.6633 - val_accuracy: 0.8428\n",
            "Epoch 70/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5746 - accuracy: 0.8561 - val_loss: 0.5813 - val_accuracy: 0.8568\n",
            "Epoch 71/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5771 - accuracy: 0.8560 - val_loss: 0.5470 - val_accuracy: 0.8673\n",
            "Epoch 72/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5694 - accuracy: 0.8575 - val_loss: 0.5883 - val_accuracy: 0.8610\n",
            "Epoch 73/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5732 - accuracy: 0.8556 - val_loss: 0.5736 - val_accuracy: 0.8606\n",
            "Epoch 74/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5761 - accuracy: 0.8555 - val_loss: 0.5549 - val_accuracy: 0.8692\n",
            "Epoch 75/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5677 - accuracy: 0.8572 - val_loss: 0.5814 - val_accuracy: 0.8612\n",
            "Epoch 76/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5727 - accuracy: 0.8577 - val_loss: 0.5681 - val_accuracy: 0.8635\n",
            "Epoch 77/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5284 - accuracy: 0.8698 - val_loss: 0.5513 - val_accuracy: 0.8707\n",
            "Epoch 78/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5217 - accuracy: 0.8713 - val_loss: 0.5201 - val_accuracy: 0.8784\n",
            "Epoch 79/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5019 - accuracy: 0.8772 - val_loss: 0.5453 - val_accuracy: 0.8724\n",
            "Epoch 80/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4910 - accuracy: 0.8768 - val_loss: 0.5497 - val_accuracy: 0.8652\n",
            "Epoch 81/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4857 - accuracy: 0.8796 - val_loss: 0.5099 - val_accuracy: 0.8776\n",
            "Epoch 82/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4881 - accuracy: 0.8773 - val_loss: 0.4933 - val_accuracy: 0.8798\n",
            "Epoch 83/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4801 - accuracy: 0.8812 - val_loss: 0.5413 - val_accuracy: 0.8685\n",
            "Epoch 84/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4761 - accuracy: 0.8808 - val_loss: 0.5196 - val_accuracy: 0.8759\n",
            "Epoch 85/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4818 - accuracy: 0.8801 - val_loss: 0.5111 - val_accuracy: 0.8767\n",
            "Epoch 86/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4776 - accuracy: 0.8795 - val_loss: 0.5063 - val_accuracy: 0.8767\n",
            "Epoch 87/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4710 - accuracy: 0.8806 - val_loss: 0.5436 - val_accuracy: 0.8648\n",
            "Epoch 88/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4663 - accuracy: 0.8817 - val_loss: 0.5071 - val_accuracy: 0.8763\n",
            "Epoch 89/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4812 - accuracy: 0.8765 - val_loss: 0.4875 - val_accuracy: 0.8834\n",
            "Epoch 90/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4633 - accuracy: 0.8829 - val_loss: 0.4815 - val_accuracy: 0.8820\n",
            "Epoch 91/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4641 - accuracy: 0.8820 - val_loss: 0.5022 - val_accuracy: 0.8790\n",
            "Epoch 92/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4532 - accuracy: 0.8853 - val_loss: 0.4790 - val_accuracy: 0.8863\n",
            "Epoch 93/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4609 - accuracy: 0.8826 - val_loss: 0.4883 - val_accuracy: 0.8793\n",
            "Epoch 94/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4552 - accuracy: 0.8850 - val_loss: 0.5275 - val_accuracy: 0.8703\n",
            "Epoch 95/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4490 - accuracy: 0.8850 - val_loss: 0.4888 - val_accuracy: 0.8798\n",
            "Epoch 96/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4566 - accuracy: 0.8821 - val_loss: 0.4926 - val_accuracy: 0.8802\n",
            "Epoch 97/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4546 - accuracy: 0.8826 - val_loss: 0.4976 - val_accuracy: 0.8756\n",
            "Epoch 98/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4588 - accuracy: 0.8820 - val_loss: 0.5037 - val_accuracy: 0.8760\n",
            "Epoch 99/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4555 - accuracy: 0.8831 - val_loss: 0.4985 - val_accuracy: 0.8737\n",
            "Epoch 100/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4491 - accuracy: 0.8854 - val_loss: 0.4704 - val_accuracy: 0.8879\n",
            "Epoch 101/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4448 - accuracy: 0.8874 - val_loss: 0.5036 - val_accuracy: 0.8792\n",
            "Epoch 102/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4363 - accuracy: 0.8882 - val_loss: 0.4878 - val_accuracy: 0.8773\n",
            "Epoch 103/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4181 - accuracy: 0.8960 - val_loss: 0.4809 - val_accuracy: 0.8849\n",
            "Epoch 104/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4270 - accuracy: 0.8900 - val_loss: 0.4766 - val_accuracy: 0.8847\n",
            "Epoch 105/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4088 - accuracy: 0.8978 - val_loss: 0.4648 - val_accuracy: 0.8833\n",
            "Epoch 106/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4158 - accuracy: 0.8937 - val_loss: 0.5205 - val_accuracy: 0.8739\n",
            "Epoch 107/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4174 - accuracy: 0.8944 - val_loss: 0.4742 - val_accuracy: 0.8844\n",
            "Epoch 108/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4077 - accuracy: 0.8956 - val_loss: 0.4529 - val_accuracy: 0.8882\n",
            "Epoch 109/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4141 - accuracy: 0.8935 - val_loss: 0.4863 - val_accuracy: 0.8820\n",
            "Epoch 110/125\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4062 - accuracy: 0.8967 - val_loss: 0.4476 - val_accuracy: 0.8900\n",
            "Epoch 111/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4049 - accuracy: 0.8947 - val_loss: 0.4417 - val_accuracy: 0.8919\n",
            "Epoch 112/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4042 - accuracy: 0.8970 - val_loss: 0.4749 - val_accuracy: 0.8804\n",
            "Epoch 113/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3941 - accuracy: 0.9010 - val_loss: 0.4526 - val_accuracy: 0.8877\n",
            "Epoch 114/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4015 - accuracy: 0.8984 - val_loss: 0.4446 - val_accuracy: 0.8898\n",
            "Epoch 115/125\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3975 - accuracy: 0.8989 - val_loss: 0.4468 - val_accuracy: 0.8872\n",
            "Epoch 116/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3979 - accuracy: 0.8962 - val_loss: 0.4536 - val_accuracy: 0.8885\n",
            "Epoch 117/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4030 - accuracy: 0.8968 - val_loss: 0.4657 - val_accuracy: 0.8851\n",
            "Epoch 118/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3864 - accuracy: 0.9004 - val_loss: 0.4461 - val_accuracy: 0.8878\n",
            "Epoch 119/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3960 - accuracy: 0.8989 - val_loss: 0.4477 - val_accuracy: 0.8898\n",
            "Epoch 120/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3950 - accuracy: 0.8992 - val_loss: 0.5054 - val_accuracy: 0.8721\n",
            "Epoch 121/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3886 - accuracy: 0.8997 - val_loss: 0.4767 - val_accuracy: 0.8828\n",
            "Epoch 122/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4042 - accuracy: 0.8937 - val_loss: 0.4511 - val_accuracy: 0.8877\n",
            "Epoch 123/125\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3905 - accuracy: 0.8985 - val_loss: 0.4705 - val_accuracy: 0.8848\n",
            "Epoch 124/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3884 - accuracy: 0.8999 - val_loss: 0.4363 - val_accuracy: 0.8922\n",
            "Epoch 125/125\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3864 - accuracy: 0.8988 - val_loss: 0.4545 - val_accuracy: 0.8895\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4545 - accuracy: 0.8895\n",
            "\n",
            "Test result: 88.950 loss: 0.455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BKVVzFG4N-o",
        "outputId": "5afbb63e-319b-4b95-9461-b372e43c40af"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.10,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.9.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3,>=2.8.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub<0.10,>=0.7.0->tensorflowjs) (54.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.27.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "Iv1CSyb4RN5A",
        "outputId": "793369fd-95a0-4072-9f02-ae096b90e829"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-bae6a7dffe0a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class L2 {\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_sWNmKb4TuX",
        "outputId": "a682c67e-7097-4e5c-9982-8e4760690460"
      },
      "source": [
        "import tensorflowjs as tfjs\n",
        "tfjs.converters.save_keras_model(model, \"tfjs_target_dir/\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  return h5py.File(h5file)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM02TRbJ4VRL",
        "outputId": "d8a9d106-1e3e-49e0-ba41-ee8cf1bdaed5"
      },
      "source": [
        "!zip -r /content/file.zip tfjs_target_dir/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: tfjs_target_dir/ (stored 0%)\n",
            "updating: tfjs_target_dir/group1-shard1of1.bin (deflated 7%)\n",
            "updating: tfjs_target_dir/model.json (deflated 90%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0WIlGlUi4Wxr",
        "outputId": "d53a1116-6547-4306-a46b-97725e06614e"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2e1edb68-2d16-4915-8da4-a48be68f2781\", \"file.zip\", 1152174)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}